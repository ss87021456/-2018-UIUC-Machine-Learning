% !TEX root = exam.tex
\input{QLearn_StudentSolution} %The students have to fill this file to print the solution


% Problem Explanation:
% - first argument is the number of points
% - second argument is the title and the text
\examproblem{13}{Q-Learning
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%  BEGINNING OF SUBPROBLEMS LIST
\begin{enumerate}

% Subproblem description
\examproblempart{State the Bellman optimality principle as a function of the optimal Q-function $Q^{*}(s,a)$, the expected reward function $R(s,a,s')$ and the transition probability $P(s'|s,a)$, where $s$ is the current state, $s'$ is the next state and $a$ is the action taken in state $s$.\\
}
\bookletskip{0}   %in inches

% Solution box 
  \framebox[14.7cm][l]{
 \begin{minipage}[b]{14.7cm}
 \inbooklet{Your answer: \QLearnStudSolA}
  
 \solution{\QLearnSolA}
 \end{minipage}
 }
 
% Subproblem description 
 \examproblempart{In case the transition probability $P(s'|s,a)$ and the expected reward $R(s,a,s')$  are unknown, a stochastic  approach is used to approximate the optimal Q-function. After observing a transition of the form $(s,a,r,s')$, write down the update of the Q-function at the observed state-action pair $(s,a)$ as a function of the learning rate $\alpha$, the discount factor $\gamma$, $Q(s,a)$ and $Q(s',a')$.\\

}
\bookletskip{0}   %in inches

% Solution box 
  \framebox[14.7cm][l]{
 \begin{minipage}[b]{14.7cm}
 \inbooklet{Your answer: \QLearnStudSolB}
  
 \solution{\QLearnSolB}
 \end{minipage}
 }

% Subproblem description
\examproblempart{What is the advantage of an epsilon-greedy strategy? \\}
\bookletskip{0.0}   %in inches
 
% Solution box  
   \framebox[14.7cm][l]{
 \begin{minipage}[b]{14.7cm}
 \inbooklet{Your answer: \QLearnStudSolC}
  
 \solution{\QLearnSolC}
 \end{minipage}
 }
 
% Subproblem description 
 \examproblempart{What is the advantage of using a replay-memory?  \\}
\bookletskip{0.0}   %in inches
 
% Solution box  
   \framebox[14.7cm][l]{
 \begin{minipage}[b]{14.7cm}
 \inbooklet{Your answer: \QLearnStudSolD}
  
 \solution{\QLearnSolD}
 \end{minipage}
 }
 

 
\bookletpage
% Subproblem description
 \examproblempart{Consider a system with two states $S_{1}$ and $S_{2}$ and two actions $a_{1}$ and $a_{2}$. You perform actions and observe the rewards and transitions listed below. Each step lists the current state, reward, action and resulting transition as: $S_{i};  R=r; a_{k}: S_{i} \rightarrow S_{j}  $. Perform Q-learning using a learning rate of $\alpha=0.5$ and a discount factor of $\gamma=0.5$ for each step by applying the formula from part (b). The Q-table entries are initialized to zero.  Fill in the tables below corresponding to the following four transitions. What is the optimal policy after having observed the four transitions?}
 
 \begin{enumerate}
\item $S_{1}$; $R=-10$; $a_{1}:S_{1}\rightarrow S_{1}$
\item  $S_{1}$; $R=-10$; $a_{2}:S_{1}\rightarrow S_{2}$
\item $S_{2}$; $R=18.5$; $a_{1}:S_{2}\rightarrow S_{1}$
\item $S_{1}$; $R=-10$; $a_{2}:S_{1}\rightarrow S_{2}$

\end{enumerate}

 

\bookletskip{0}   %in inches


\begin{table}[h]
\small       
\begin{tabular}[t]{|c c c|}
\hline
$Q$ & $S_{1}$ & $S_{2}$  \\ \hline
$a_{1}$&.&.\\ \hline
$a_{2}$&.& .\\ \hline
\end{tabular}
\hfill
\begin{tabular}[t]{|c c c|}
\hline
$Q$ & $S_{1}$ & $S_{2}$  \\ \hline
$a_{1}$&.&.\\ \hline
$a_{2}$&.&.\\ \hline
\end{tabular}
\hfill
\begin{tabular}[t]{|c c c|}
 \hline
 $Q$ & $S_{1}$ & $S_{2}$  \\ \hline
 $a_{1}$&.&.\\ \hline
 $a_{2}$&.&. \\ \hline
 \end{tabular}
 \hfill
 \begin{tabular}[t]{|c c c|}
 \hline
 $Q$ & $S_{1}$ & $S_{2}$  \\ \hline
 $a_{1}$&.&.\\ \hline
 $a_{2}$&.&. \\ \hline
\end{tabular}
\end{table}

% Solution box 
  \framebox[14.7cm][l]{
 \begin{minipage}[b]{14.7cm}
 \inbooklet{Your answer: \QLearnStudSolE}
  
 \solution{\QLearnSolE}
 \end{minipage}
 }
 
%%%%%%%%%%%% END OF SUBPROBLEMS LIST

\end{enumerate}